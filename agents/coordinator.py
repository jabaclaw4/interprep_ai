# agents/coordinator.py
import json
import sys
from pathlib import Path
from pydantic import BaseModel
from gigachat import GigaChat
from dotenv import load_dotenv
import os
from typing import Dict, Any, Optional

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.append(str(Path(__file__).resolve().parent.parent))

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º RAG (—Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫)
try:
    from rag.retriever import retrieve_context

    RAG_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  RAG –º–æ–¥—É–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω. Coordinator –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.")
    RAG_AVAILABLE = False


    def retrieve_context(query: str, k: int = 4) -> list:
        return []

load_dotenv()


class RouteResult(BaseModel):
    agent: str
    context: str
    metadata: dict
    confidence: float
    suggested_topics: Optional[list] = None
    rag_context_used: Optional[bool] = False


class CoordinatorAgent:
    def __init__(self, use_rag: bool = True):
        load_dotenv()
        self.client_secret = os.getenv("GIGACHAT_CLIENT_SECRET")
        if not self.client_secret:
            raise ValueError("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω GIGACHAT_CLIENT_SECRET –≤ .env")

        self.llm = GigaChat(
            credentials=self.client_secret,
            verify_ssl_certs=False,
            model="GigaChat"
        )
        self.use_rag = use_rag and RAG_AVAILABLE
        self.user_states = {}  # user_id -> state

    def route(self, user_text: str, user_context: dict = None, user_id: str = None) -> RouteResult:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏"""

        if user_context is None:
            user_context = {}

        state = self.user_states.get(user_id, {})
        current_mode = state.get('mode')

        print(f"üîç Coordinator: '{user_text[:50]}...', mode={current_mode}, user_id={user_id}")

        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å–ª–∏ —ç—Ç–æ –ø—Ä—è–º–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤ –ø–æ—Å–ª–µ /assess
        if current_mode == 'awaiting_assessment_details':
            # –û—á–∏—â–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫ ASSESSOR
            if user_id in self.user_states:
                self.user_states[user_id]['mode'] = 'assessment_in_progress'
                self.user_states[user_id]['skills'] = user_text

            return RouteResult(
                agent="ASSESSOR",
                context=f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ–ø–∏—Å–∞–ª –Ω–∞–≤—ã–∫–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏: {user_text[:100]}...",
                metadata={
                    "action": "process_skills",
                    "skills_text": user_text,
                    "source": "assessment_flow"
                },
                confidence=0.95,
                suggested_topics=["Python", "Django", "Backend"],
                rag_context_used=False
            )

        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å–ª–∏ —ç—Ç–æ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤ (–¥–∞–∂–µ –±–µ–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è)
        text_lower = user_text.lower()

        # –Ø–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –æ–ø–∏—Å–∞–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤
        skill_indicators = [
            '–∑–Ω–∞—é', '–æ–ø—ã—Ç', '—Ä–∞–±–æ—Ç–∞–ª', '–≤–ª–∞–¥–µ—é', '—É–º–µ—é',
            'python', 'django', 'java', 'javascript',
            '–≥–æ–¥', '–ª–µ—Ç', '–º–µ—Å—è—Ü', '–ø—Ä–æ–µ–∫—Ç'
        ]

        skill_count = sum(1 for indicator in skill_indicators if indicator in text_lower)
        has_comma = ',' in user_text
        word_count = len(user_text.split())

        # –ï—Å–ª–∏ –ø–æ—Ö–æ–∂–µ –Ω–∞ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤
        if skill_count >= 2 and (has_comma or word_count >= 4):
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            if user_id:
                self.user_states[user_id] = {
                    'mode': 'assessment_in_progress',
                    'skills': user_text
                }

            return RouteResult(
                agent="ASSESSOR",
                context=f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è",
                metadata={
                    "action": "assess_skills",
                    "skill_indicators_found": skill_count,
                    "text_length": word_count
                },
                confidence=0.85,
                rag_context_used=False
            )

        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—Ä—É–≥–∏–µ —Ç–∏–ø—ã –∑–∞–ø—Ä–æ—Å–æ–≤
        # –ü–ª–∞–Ω –æ–±—É—á–µ–Ω–∏—è
        plan_keywords = ['—Ö–æ—á—É –∏–∑—É—á–∞—Ç—å', '–Ω–∞—É—á–∏—Ç—å—Å—è', '–æ—Å–≤–æ–∏—Ç—å', '–∏–∑—É—á', '–æ–±—É—á', '–ø–ª–∞–Ω–∏—Ä']
        if any(keyword in text_lower for keyword in plan_keywords):
            if user_id:
                self.user_states[user_id] = {'mode': 'planning'}

            return RouteResult(
                agent="PLANNER",
                context=f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç —Å–æ–∑–¥–∞—Ç—å –ø–ª–∞–Ω –æ–±—É—á–µ–Ω–∏—è",
                metadata={"intent": "learning_plan"},
                confidence=0.8,
                rag_context_used=False
            )

        # –°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ
        interview_keywords = ['—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω', '–∏–Ω—Ç–µ—Ä–≤—å—é', '–≤–æ–ø—Ä–æ—Å—ã', 'mock']
        if any(keyword in text_lower for keyword in interview_keywords):
            return RouteResult(
                agent="INTERVIEWER",
                context=f"–ó–∞–ø—Ä–æ—Å –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ",
                metadata={"intent": "interview"},
                confidence=0.8,
                rag_context_used=False
            )

        # Code review
        code_keywords = ['–∫–æ–¥', '—Ä–µ—à–µ–Ω', '–∑–∞–¥–∞—á', '–∞–ª–≥–æ—Ä–∏—Ç–º']
        if any(keyword in text_lower for keyword in code_keywords):
            return RouteResult(
                agent="REVIEWER",
                context=f"–ó–∞–ø—Ä–æ—Å –Ω–∞ —Ä–∞–∑–±–æ—Ä –∫–æ–¥–∞",
                metadata={"intent": "code_review"},
                confidence=0.8,
                rag_context_used=False
            )

        # 4. –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–¥–æ—à–ª–æ - –æ–±—â–∏–π –ø–æ–º–æ—â–Ω–∏–∫
        return RouteResult(
            agent="HELPER",
            context="–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å",
            metadata={"fallback": True, "text_analysis": "no_clear_intent"},
            confidence=0.3,
            rag_context_used=False
        )

    def set_user_state(self, user_id: str, mode: str, data: dict = None):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        if data is None:
            data = {}

        self.user_states[user_id] = {
            'mode': mode,
            **data
        }
        print(f"‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è {user_id}: {mode}")

    def clear_user_state(self, user_id: str):
        """–û—á–∏—â–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        if user_id in self.user_states:
            del self.user_states[user_id]
            print(f"‚úÖ –û—á–∏—â–µ–Ω–æ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è {user_id}")